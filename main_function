library(remotes)
library(sampling)
library(survey)
library(nonprobsvy)
library(ggplot2)
library(pps)
library(compositions)
library(robustbase)
# library(cem)
library(MatchIt)
# library(tidyverse)
library(dummies)
library(MASS)

library(plyr)
library(KWML)
library(lme4)
library(depmixS4)
library(snowfall)
library(pROC)


##############################################################################################
###########################################To calculate the kernel smoothed value
##############################################################################################
K <- function(x) {(1 / sqrt(2 * pi)) * exp(-x^2 / 2)}

##############################################################################################
###########################################To calcuate the variance
##############################################################################################
#############################################################################
# FUNCTION v2_fun is a function to calculate complete TL variance for a     #
#          pseudo-weighted estimate of finite population mean. No clustering#
#          or stratification is considered for either cohort or survey      #
# INPUT                                                                     #
#  pw:        pseudo-weight                                                 #
#  pw_beta:   partial derivative of pw w.r.t propensity model coefficients  #
#  mu_hat:    estimate of finite population mean                            #
#  model.par: a list including estimated PS and design matrix for cohort and#
#             survey sample                                                 #
#  y:         variable of interest                                          #
#  svy.wt:    vector of survey sample weights                               #
# OUTPUT                                                                    #
#  v_all: variance matrix of the propensity model coefficients and mu       #
#############################################################################
v2_fun = function(pw, pw_beta, mu_hat, model.par, y, svy.wt){
  # Propensity score for cohort and survey sample
  p.c = model.par$p.c; p.s = model.par$p.s 
  # design matrix for cohort and survey sample
  design.x.c = model.par$design.x.c; design.x.s = model.par$design.x.s
  # sample size for cohort and survey sample
  n_c = length(p.c); n_s = length(p.s)
  # Take derivative of Phi w.r.t mu and beta (phi), and phi inverse
  U_mu   = -sum(pw); U_beta = c(y-mu_hat)%*%pw_beta
  S_mu   = rep(0, dim(pw_beta)[2])
  S_beta = -t(p.c*(1-p.c)*design.x.c)%*%design.x.c-
    t(svy.wt* p.s*(1-p.s)*design.x.s)%*%design.x.s
  S_beta_inv = solve(S_beta); b=-1/U_mu*U_beta%*%S_beta_inv
  phi_inv = rbind(c(1/U_mu, b), cbind(S_mu, S_beta_inv))
  # Calculate var(Phi)
  Phi_1  = as.data.frame(cbind(pw*(y-mu_hat), (1-p.c)*design.x.c))
  Phi_2  = -as.data.frame(cbind(0, svy.wt* p.s*design.x.s))
  v1 = var(Phi_1)*n_c; v2 = var(Phi_2)*n_s; v_Phi = v1+v2 
  v_all = phi_inv%*%v_Phi%*%t(phi_inv)
  return(list(v_all=v_all))
} # End FUNCTION v2_fun

##############################################################################################
###########################################Main function
##########################################################################################################
##########################################################################################################
# Parameter description                                                                                   #
# data_NP: nonprobability sample                                                                          #
# data_P: reference sample                                                                                #
# CIV: list of names of common covarates                                                                  #
# type_CIV: list of type of common covaroates,possible values inlcude 'guassian','binomial','multinomial' #
# DV_NP: outcome                                                                                          #
# DV_type:type of outcome,possible values inlcude'guassian','binomial'                                    #
# sample_w:sample weight of refernce sample                                                               #
# maxclassnum:upper limit of latent classes                                                               #
###########################################################################################################
NPinfer_ALC <-
  function(data_NP=data_A,data_P=data_B,
           CIV=c('X1','X2','X3','X4','X5'),type_CIV=c('binomial','gaussian','gaussian','gaussian','gaussian'),
           DV_NP='Y',DV_type='gaussian',sample_weight='sample_weight',
           maxclassnum=5)
  {
    #################################################################################################
    ##################################################################################数据预处理-----
    #################################################################################################
    
    #calculate scaling factor a
    a <- 1-nrow(data_P)/sum(data_P[,sample_weight])
    
    #calculate scaling weights for reference sample
    SW_P <- data_P[,sample_weight]*a
    OSW_P <- data_P[,sample_weight]
    data_P <- cbind(data_P,SW=SW_P,OSW=OSW_P)
    
    #define weighting variables for nonprobability sample and reference sample, respectively
    SW_NP <- rep(1,times=nrow(data_NP))
    OSW_NP <- rep(1,times=nrow(data_NP))
    data_NP <- cbind(data_NP,SW=SW_NP,OSW=OSW_NP)

    #geneting the id variable
    id <- 1:length(nrow(data_NP)+nrow(data_P))
    
    #combine the two samples
    data_com <- cbind(rbind.fill(cbind(data_NP,group=1),cbind(data_P,group=0)),id)
    
    #################################################################################################
    ################################################################Stage 1:Identification of heterogeneous populations using finite mixture modelling-------
    #################################################################################################
    data_com1 <- data_com
    for (CIV_i in 1:length(CIV)) {
      if(type_CIV[CIV_i]=='binomial'){ data_com1[,CIV[CIV_i]] <- as.numeric(factor(data_com1[,CIV[CIV_i]]))-1 }
      
      if(type_CIV[CIV_i]=='multinomial'){ data_com1[,CIV[CIV_i]] <- as.numeric(factor(data_com1[,CIV[CIV_i]])) }

      if(type_CIV[CIV_i]=='gaussian'){ data_com1[,CIV[CIV_i]] <- data_com1[,CIV[CIV_i]] }
    }
    
    #model expression for identifying latent classes
    expr_variable <- paste('list(',paste(paste(CIV,'~1',sep=''),collapse = ','),')',sep='')
    expr_type <- paste('list(',paste(paste(type_CIV,'()',sep=''),collapse = ','),')',sep='')
    
    BIC <- NULL;results_FM <- NULL
    for (i_class in 1:maxclassnum) {
      lca <- depmixS4::mix(eval(str2lang(expr_variable)),
                           data=data_com1,
                           nstates = i_class,
                           family = eval(str2lang(expr_type)))
      Ind_lca1 <- try(fit <- fit(lca),silent=TRUE)
      
      #防止上面的模型跑不出来，设置一个while循环让它可以跑出来为止
      T <- 0
      while(methods::is(Ind_lca1,"try-error")==TRUE & T<=10) {
        lca <- depmixS4::mix(eval(str2lang(expr_variable)),
                             data=data_com1,
                             nstates = i_class,
                             family = eval(str2lang(expr_type)))
        Ind_lca1 <- try(fit <- fit(lca),silent=TRUE)
        T <- T+1
      }
      if(methods::is(Ind_lca1,"try-error")==TRUE){stop('The finite mixture model cannot be fitted')}
      
      BIC[i_class] <- BIC(fit)
      results_FM <- cbind(results_FM,fit@posterior$state)
    }
    bestnum_vec <- which(BIC==min(BIC))
    if(length(bestnum_vec)>=1){bestnum <- bestnum_vec[1]}
    if(length(bestnum_vec)==1){bestnum <- bestnum_vec}
    LC <- results_FM[,bestnum]
    
    #################################################################################################
    ################################################################stage 2:Construction of propensity score model and outcome projection model accounting for population heterogeneity -------
    #################################################################################################
    
    #transform the multinomial variables to dummy variables
    data_com2 <- cbind(data_com,LC)
    CIV_2 <- NULL
    
    for (CIV_i in 1:length(CIV)){
      
      if(type_CIV[CIV_i]=='binomial'){ 
        data_com2[,CIV[CIV_i]] <- as.numeric(factor(data_com2[,CIV[CIV_i]]))-1 
        CIV_2 <- c(CIV_2,CIV[CIV_i])
      }
      
      if(type_CIV[CIV_i]=='multinomial'){ 
        dummy_var <- model.matrix(~ data_com2[,CIV[CIV_i]] - 1, data = data_com2)
        dummy_num <- length(unique(data_com2[,CIV[CIV_i]]))
        dummy_name <- paste(CIV[CIV_i],1:dummy_num,sep='')
        colnames(dummy_var) <- dummy_name
        dummy_var2 <- dummy_var[,-1]
        data_com2 <- cbind(data_com2,dummy_var)
        dummy_name2 <- colnames(dummy_var2)
        CIV_2 <- c(CIV_2,dummy_name2)
      }
      
      if(type_CIV[CIV_i]=='gaussian'){ 
        data_com2[,CIV[CIV_i]] <- data_com2[,CIV[CIV_i]] 
        CIV_2 <- c(CIV_2,CIV[CIV_i])
      }
      
    }
    
    #when the optimal number of latent classes is 1, use directly the GLM
    if(bestnum==1){
      #separate the two sample
      data_NP2 <- data_com2[data_com2$group==1,]
      data_P2 <- data_com2[data_com2$group==0,]
      
      #fit the propensity score model
      formula_myipw <- paste('group~',paste(CIV_2,collapse = '+'),sep='')
      fit_toNP <- glm(eval(str2lang(formula_myipw)), data=data_com2, family='binomial', weights = SW)
      
      #fit the outcome projection model
      formula_mysp <- paste(DV_NP,'~',paste(CIV_2,collapse = '+'),sep='')
      fit_Y <- glm(eval(str2lang(formula_mysp)), data=data_NP2,family=DV_type)
    }#bestnum==1
    
    #when the optimal number of latent classed is more than 1, use the mixed-effects models
    if(bestnum!=1){
      #separate the two sample
      data_NP2 <- data_com2[data_com2$group==1,]
      data_P2 <- data_com2[data_com2$group==0,]
      
      #fit the propensity score model
      formula_myipw <- paste('group~(',paste(CIV_2,collapse = '+'),'|LC)',sep='')
      suppressWarnings(fit_toNP <- glmer(eval(str2lang(formula_myipw)), data=data_com2, family=binomial, weights = SW))
      
      #fit the outcome projection model
      formula_mysp <- paste(DV_NP,'~(',paste(CIV_2,collapse = '+'),'|LC)',sep='')
      suppressWarnings(fit_Y <- glmer(eval(str2lang(formula_mysp)), data=data_NP2,family=DV_type))
    }#bestnum!=1
    
    #################################################################################################
    ################################################################estimate the kernel smoothed weights------
    #################################################################################################
    
    #estimate the propensity score of the combined sample
    ps_BOTH <- predict(fit_toNP, newdata=data_com2, type="link")
    #select the propensity score of nonprobability sample
    ps_NP <- ps_BOTH[data_com2$group==1]
    #select the propensity score of reference sample
    ps_P <- ps_BOTH[data_com2$group==0]
    #scaled weights of reference sample
    sweight_P <- data_com2[data_com2$group==0,'SW']
    #kernel smoothed weigths of nonprobability sample
    fit_kernal <- kw.wt(p_score.c = ps_NP,p_score.s = ps_P,svy.wt = sweight_P,krn = "dnorm")
    kwweight_NP <- fit_kernal$pswt
    point_kwipw <- sum(data_NP2[,DV_NP]*kwweight_NP)/sum(kwweight_NP)
    h <- fit_kernal$h
    
    #####################################################################################estimate the variance
    #projected outcome of the two sample
    PP_P <- predict(fit_toNP, newdata=data_P2, type="response")
    PP_NP <- predict(fit_toNP, newdata=data_NP2, type="response")
    #design matrix of the two sample
    design_matrix_NP <- data_com2[data_com2$group==1,CIV_2]
    design_matrix_P <- data_com2[data_com2$group==0,CIV_2]
    #number of common covariates; sample size of nonprobability sample
    n_CIV <- ncol(design_matrix_NP);n_NP <- nrow(design_matrix_NP)
    #estimate distance matrix 
    sgn_dist_mtx <- outer(ps_P,ps_NP,FUN = '-')
    #kernel smoothing the distance matrix
    krn_num <- K(sgn_dist_mtx/h)
    #summing the kernel smoothed matrix
    row.krn = rowSums(krn_num)
    #calculate the first derivative
    pw_beta=matrix(0, n_NP, n_CIV)
    for(i in 1:n_CIV){
      design.x.dist=outer(design_matrix_P[,i], design_matrix_NP[,i], FUN="-")
      kij_beta = -krn_num*sgn_dist_mtx*design.x.dist/h^2  
      row.kij_beta = rowSums(kij_beta)                    
      deriv1= (sweight_P/row.krn)%*%kij_beta
      deriv2= -(sweight_P*row.kij_beta/row.krn/row.krn)%*%krn_num
      pw_beta[,i] = deriv1+deriv2}
    #define the parameter list
    model.par <- list(p.c=PP_NP,p.s=PP_P,design.x.c=as.matrix(design_matrix_NP),design.x.s=as.matrix(design_matrix_P))
    #estimate the variance
    V_kwipw <- v2_fun(pw=kwweight_NP, pw_beta=pw_beta, mu_hat=point_kwipw, model.par=model.par, y=data_NP2[,DV_NP], svy.wt=sweight_P)$v_all[1,1]
    #estimate the confidence interval
    CI_kwipw <- data.frame('lower_bound'=point_kwipw-1.96*sqrt(V_kwipw),'upper_bound'=point_kwipw+1.96*sqrt(V_kwipw))
    
    #################################################################################################
    ################################################################estimate the projected outcome in the reference sample------
    #################################################################################################
    
    #estimate the projected outcome in reference sample
    if(DV_type=='gaussian'){PDV_P <- predict(fit_Y, newdata=data_P2)}
    if(DV_type=='binomial'){
      PDV_P <- predict(fit_Y, newdata=data_P2,type='response')
      }
    sweight2_P <- data_P2[,'OSW']
    PDV_svydesign <- svydesign(ids=~1, weights=sweight2_P,  data=data.frame(sweight2_P,PDV_P))
    out_PDV <- svymean(~PDV_P,PDV_svydesign)
    
    #point estiamte
    point_newsp <- out_PDV[[1]]
    #variance estimate
    V_newsp <- attr(out_PDV,"var")[1]
    #confidence interval estimate
    CI_newsp <- data.frame('lower_bound'=point_newsp-1.96*sqrt(V_newsp),'upper_bound'=point_newsp+1.96*sqrt(V_newsp))
    
    #################################################################################################
    ################################################################Construction of a doubly robust estimator-----
    #################################################################################################
    
    #estimate projected outcome in the nonprobability sample
    if(DV_type=='gaussian'){PDV_NP <- predict(fit_Y, newdata=data_NP2)}
    if(DV_type=='binomial'){
      PDV_NP <- predict(fit_Y, newdata=data_NP2,type='response')
      }
    #point estimate of doubly robust estimator
    point_kwdr <- (sum((data_NP2[,DV_NP]-PDV_NP)*kwweight_NP)/sum(kwweight_NP)) + point_newsp
    #residual vector
    redidual_P <- data_NP2[,DV_NP]-PDV_NP
    point_redidual_P <- (sum((data_NP2[,DV_NP]-PDV_NP)*kwweight_NP)/sum(kwweight_NP))
    #variance estimate
    V_dr_1 <- v2_fun(pw=kwweight_NP, pw_beta=pw_beta, mu_hat=point_redidual_P, model.par=model.par, y=redidual_P, svy.wt=sweight_P)$v_all[1,1]
    #summing the variance from two two parts
    V_dr <- V_dr_1+V_newsp
    #confidence interval
    CI_kwdr <- data.frame('lower_bound'=point_kwdr-1.96*sqrt(V_dr),'upper_bound'=point_kwdr+1.96*sqrt(V_dr))
    
    
    ################################################################output
    output <- list('point_kwdr'=point_kwdr,'CI_kwdr'=CI_kwdr)
    return(output)
    
  }#function:NPinfer_ALC
